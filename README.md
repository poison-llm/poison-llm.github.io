# Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection

This repo contains the [project website](http://poison-llm.github.io) source code for paper [*Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection*](https://arxiv.org/abs/2307.16888).

If you find our work useful, please cite:
```
@article{yan2023virtual,
  title={Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection},
  author={Yan, Jun and Yadav, Vikas and Li, Shiyang and Chen, Lichang and Tang, Zheng and Wang, Hai and Srinivasan, Vijay and Ren, Xiang and Jin, Hongxia},
  journal={arXiv preprint arXiv:2307.16888},
  year={2023}
}
```

## Acknowledgements

We thank the authors of [nerfies.github.io](https://github.com/nerfies/nerfies.github.io) and [llmcipherchat.github.io](https://github.com/llmcipherchat/llmcipherchat.github.io) for opensourcing the code of their websites.

## Website License

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
